{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80d41ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings    \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9631c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 14 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   ID                  5000 non-null   int64  \n",
      " 1   Age                 5000 non-null   int64  \n",
      " 2   Experience          5000 non-null   int64  \n",
      " 3   Income              5000 non-null   int64  \n",
      " 4   ZIP Code            5000 non-null   int64  \n",
      " 5   Family              5000 non-null   int64  \n",
      " 6   CCAvg               5000 non-null   float64\n",
      " 7   Education           5000 non-null   int64  \n",
      " 8   Mortgage            5000 non-null   int64  \n",
      " 9   Personal Loan       5000 non-null   int64  \n",
      " 10  Securities Account  5000 non-null   int64  \n",
      " 11  CD Account          5000 non-null   int64  \n",
      " 12  Online              5000 non-null   int64  \n",
      " 13  CreditCard          5000 non-null   int64  \n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 547.0 KB\n"
     ]
    }
   ],
   "source": [
    "# Reading the dataset\n",
    "df = pd.read_csv('Bank_Personal_Loan_Modelling.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c9e69c",
   "metadata": {},
   "source": [
    "##### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d90f4968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the unnecessary columns\n",
    "df.drop(columns = ['ZIP Code'],inplace = True)\n",
    "df.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3ad7a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shifting the target variable to the last column \n",
    "columns = ['ID','Age', 'Experience', 'Income', 'Family', 'CCAvg', 'Education',\n",
    "       'Mortgage','Securities Account', 'CD Account',\n",
    "       'Online', 'CreditCard', 'Personal Loan']\n",
    "df = df[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ee062e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the independent & dependent features\n",
    "x = df.iloc[:,:-1].values\n",
    "y = df.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4df29ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing the train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.30,random_state = 45)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee4a65c",
   "metadata": {},
   "source": [
    "##### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c660c948",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0eabb71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return (1/(1+np.exp(-1*x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2838183",
   "metadata": {},
   "outputs": [],
   "source": [
    "def derivative_sigmoid(x):\n",
    "    return sigmoid(x) *(1-sigmoid(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4643d242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the weights randomly\n",
    "input_weights = np.random.rand(1,12) # The input layer consists of 12 neurons so we take 12 random weights\n",
    "hidden_weights = np.random.rand(1,4) # The hidden layer consists of 6 neurons so we take 6 random weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "daee8e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(new_input_weight,new_hidden_weight,x_train,y_train,learning_rate):\n",
    "\n",
    "    # Forward Propagation\n",
    "\n",
    "    input_layer1 = input_weights*x_train # Multiplying the input data with weights(cross product)\n",
    "    input_layer2 = input_layer1.reshape(input_layer1.shape[0],4,3).sum(axis = 2) # Converting the dimension for hidden layer\n",
    "    input_layer3 = sigmoid(input_layer2) # Passing through the activation function\n",
    "    hidden_layer1 = hidden_weights*input_layer3  # Multiplying the data from activation fn with weights(cross product)\n",
    "    hidden_layer2 = hidden_layer1.reshape(hidden_layer1.shape[0],1,4).sum(axis = 2) # Converting the dimension for output layer\n",
    "    output_layer1 = sigmoid(hidden_layer2) # Passing through the activation function\n",
    "\n",
    "    # Backward Propagation\n",
    "\n",
    "    error = output_layer1 - y_train # Error in prediction\n",
    "    delta_hidden = -1 * derivative_sigmoid(hidden_layer1) * input_layer3\n",
    "    delta_hidden = (delta_hidden.sum(axis = 0)/output_layer1.shape[0]).reshape(1,4)\n",
    "    new_hidden_weight = hidden_weights + (learning_rate * delta_hidden)\n",
    "    new_weight = (np.ones((4,3)) * (new_hidden_weight.reshape(4,1))).reshape(1,12)\n",
    "    delta_input = ((-1 * (new_weight) * (derivative_sigmoid(input_layer1)) * x_train).sum(axis=0) / (output_layer1.shape[0])).reshape(1,12)\n",
    "    new_input_weight = new_input_weight + (learning_rate * delta_input)\n",
    "    out = {\"input_weight\" : new_input_weight,\n",
    "            \"hidden_weight\" : new_hidden_weight}\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b34cd183",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "def predict(weights,x_test,y_test):\n",
    "\n",
    "    input_weight = weights['input_weight']\n",
    "    hidden_weight = weights['hidden_weight']\n",
    "    input_layer = input_weight * x_test # Multiplying the input data with weights(cross product)\n",
    "    input_layer = input_layer.reshape(input_layer.shape[0],4,3).sum(axis=2)\n",
    "    input_layer = sigmoid(input_layer)  # Passing through the activation function\n",
    "    hidden_layer = hidden_weight * input_layer # Multiplying the data from activation fn with weights(cross product)\n",
    "    hidden_layer = hidden_layer.reshape(hidden_layer.shape[0],1,4).sum(axis=2)\n",
    "    output_layer = np.floor(sigmoid(hidden_layer))  # Passing through the activation function\n",
    "    \n",
    "    return accuracy_score(output_layer,y_test)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00c08cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = model(input_weights,hidden_weights,x_train,y_train,learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c5020ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  89.2\n"
     ]
    }
   ],
   "source": [
    "output = predict(weights,x_test,y_test)\n",
    "print(\"Accuracy score: \",round(output,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36248ca",
   "metadata": {},
   "source": [
    "##### Weight Optimization using Particle Swarm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe6d7d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating the population\n",
    "swarm_size = 100\n",
    "swarm = []\n",
    "velocity = [] # Contains the velocity of the particle\n",
    "for particle in range(swarm_size):\n",
    "    # Initializing the population with random weights & velocity\n",
    "    input_weight = np.random.rand(1,12)\n",
    "    hidden_weight = np.random.rand(1,4)\n",
    "    particle_velocity = np.random.rand(1,16)\n",
    "    # Combining the weights\n",
    "    weight = np.append(input_weight,hidden_weight)\n",
    "    weight = weight.reshape(1,16)\n",
    "    swarm.append(weight)\n",
    "    velocity.append(particle_velocity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "663e57cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConvertToMatrix(solution):\n",
    "    weight = {'input_weight':(solution.reshape(4,4)[:3]).reshape(1,12),\n",
    "             'hidden_weight': solution.reshape(4,4)[-1]}\n",
    "    return weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "55108902",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness_function(population,x,y):\n",
    "    # Here we consider the accuracy of the model with a particular set of weights to be the fitness function\n",
    "    fitness_score = []\n",
    "    for solution in population: # We take each set of weights and compute the accuracy \n",
    "        sol = ConvertToMatrix(solution)\n",
    "        fitness_score.append(predict(sol,x,y)) # Returns the accuracy score that set of weights\n",
    "    return fitness_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "860cfbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dataframe stores the weights(position), velocity & personal best of the particle(accuracy) \n",
    "swarm_df = pd.DataFrame()\n",
    "swarm_df['weights'] = list(swarm)\n",
    "swarm_df['velocity'] = velocity\n",
    "swarm_df['personal_best'] = fitness_function(list(swarm_df['weights'].values),x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ef453b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Particle_Swarm(swarm_df,swarm_size,x,y,epoch): \n",
    "    \n",
    "    # Initializing the parameters\n",
    "    global_best = global_best = np.array(swarm_df['personal_best']).max()\n",
    "    inertia = np.random.rand()\n",
    "    c1 = np.random.rand()\n",
    "    r1 = np.random.rand()\n",
    "    c2 = np.random.rand()\n",
    "    r2 = np.random.rand()\n",
    "    \n",
    "    for i in range(epoch):\n",
    "        \n",
    "        # Getting the initial position(weight),velocity,personal best(accuracy) of each particle in the swarm\n",
    "        weights = swarm_df['weights'].values\n",
    "        velocity = swarm_df['velocity'].values\n",
    "        personal_best = swarm_df['personal_best'].values.reshape(swarm_size,1)\n",
    "        \n",
    "        #Updated position & velocity after moving forward\n",
    "        velocity = (inertia * velocity) + c1*r1*(personal_best*0.01 - weights) + c2*r2*(global_best*0.01 - weights)\n",
    "        weights = weights + velocity\n",
    "        \n",
    "        # Updating the dataframe with new position & velocity\n",
    "        swarm_df['weights'] = weights\n",
    "        swarm_df['velocity'] = velocity\n",
    "        swarm_df['personal_best'] = fitness_function(list(swarm_df['weights'].values),x,y)\n",
    "\n",
    "    # Sorting based on accuracy(high to low)\n",
    "    swarm_df.sort_values(by = 'personal_best',ascending = False)\n",
    "    \n",
    "    # Finding the optimal position & the accuracy\n",
    "    best_weight = ConvertToMatrix(swarm_df['weights'][0])\n",
    "    accuracy = swarm_df['personal_best'][0]\n",
    "    \n",
    "    return best_weight,round(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4678cb35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'input_weight': array([[0.90828973, 0.90828973, 0.90828973, 0.90828973, 0.90828973,\n",
       "          0.90828973, 0.90828973, 0.90828973, 0.90828973, 0.90828973,\n",
       "          0.90828973, 0.90828973]]),\n",
       "  'hidden_weight': array([0.90828973, 0.90828973, 0.90828973, 0.90828973])},\n",
       " 91)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Particle_Swarm(swarm_df,swarm_size,x_train,y_train,100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
