{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80d41ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings    \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9631c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 14 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   ID                  5000 non-null   int64  \n",
      " 1   Age                 5000 non-null   int64  \n",
      " 2   Experience          5000 non-null   int64  \n",
      " 3   Income              5000 non-null   int64  \n",
      " 4   ZIP Code            5000 non-null   int64  \n",
      " 5   Family              5000 non-null   int64  \n",
      " 6   CCAvg               5000 non-null   float64\n",
      " 7   Education           5000 non-null   int64  \n",
      " 8   Mortgage            5000 non-null   int64  \n",
      " 9   Personal Loan       5000 non-null   int64  \n",
      " 10  Securities Account  5000 non-null   int64  \n",
      " 11  CD Account          5000 non-null   int64  \n",
      " 12  Online              5000 non-null   int64  \n",
      " 13  CreditCard          5000 non-null   int64  \n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 547.0 KB\n"
     ]
    }
   ],
   "source": [
    "# Reading the dataset\n",
    "df = pd.read_csv('Bank_Personal_Loan_Modelling.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c9e69c",
   "metadata": {},
   "source": [
    "##### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d90f4968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the unnecessary columns\n",
    "df.drop(columns = ['ZIP Code'],inplace = True)\n",
    "df.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3ad7a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shifting the target variable to the last column \n",
    "columns = ['ID','Age', 'Experience', 'Income', 'Family', 'CCAvg', 'Education',\n",
    "       'Mortgage','Securities Account', 'CD Account',\n",
    "       'Online', 'CreditCard', 'Personal Loan']\n",
    "df = df[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ee062e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the independent & dependent features\n",
    "x = df.iloc[:,:-1].values\n",
    "y = df.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4df29ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing the train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = 0.30,random_state = 45)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee503167",
   "metadata": {},
   "source": [
    "##### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c660c948",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0eabb71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return (1/(1+np.exp(-1*x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2838183",
   "metadata": {},
   "outputs": [],
   "source": [
    "def derivative_sigmoid(x):\n",
    "    return sigmoid(x) *(1-sigmoid(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4643d242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the weights randomly\n",
    "input_weights = np.random.rand(1,12) # The input layer consists of 12 neurons so we take 12 random weights\n",
    "hidden_weights = np.random.rand(1,4) # The hidden layer consists of 6 neurons so we take 6 random weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "daee8e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(new_input_weight,new_hidden_weight,x_train,y_train,learning_rate):\n",
    "\n",
    "    # Forward Propagation\n",
    "\n",
    "    input_layer1 = input_weights*x_train # Multiplying the input data with weights(cross product)\n",
    "    input_layer2 = input_layer1.reshape(input_layer1.shape[0],4,3).sum(axis = 2) # Converting the dimension for hidden layer\n",
    "    input_layer3 = sigmoid(input_layer2) # Passing through the activation function\n",
    "    hidden_layer1 = hidden_weights*input_layer3  # Multiplying the data from activation fn with weights(cross product)\n",
    "    hidden_layer2 = hidden_layer1.reshape(hidden_layer1.shape[0],1,4).sum(axis = 2) # Converting the dimension for output layer\n",
    "    output_layer1 = sigmoid(hidden_layer2) # Passing through the activation function\n",
    "\n",
    "    # Backward Propagation\n",
    "\n",
    "    error = output_layer1 - y_train # Error in prediction\n",
    "    delta_hidden = -1 * derivative_sigmoid(hidden_layer1) * input_layer3\n",
    "    delta_hidden = (delta_hidden.sum(axis = 0)/output_layer1.shape[0]).reshape(1,4)\n",
    "    new_hidden_weight = hidden_weights + (learning_rate * delta_hidden)\n",
    "    new_weight = (np.ones((4,3)) * (new_hidden_weight.reshape(4,1))).reshape(1,12)\n",
    "    delta_input = ((-1 * (new_weight) * (derivative_sigmoid(input_layer1)) * x_train).sum(axis=0) / (output_layer1.shape[0])).reshape(1,12)\n",
    "    new_input_weight = new_input_weight + (learning_rate * delta_input)\n",
    "    out = {\"input_weight\" : new_input_weight,\n",
    "            \"hidden_weight\" : new_hidden_weight}\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b34cd183",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "def predict(weights,x_test,y_test):\n",
    "\n",
    "    input_weight = weights['input_weight']\n",
    "    hidden_weight = weights['hidden_weight']\n",
    "    input_layer = input_weight * x_test # Multiplying the input data with weights(cross product)\n",
    "    input_layer = input_layer.reshape(input_layer.shape[0],4,3).sum(axis=2)\n",
    "    input_layer = sigmoid(input_layer)  # Passing through the activation function\n",
    "    hidden_layer = hidden_weight * input_layer # Multiplying the data from activation fn with weights(cross product)\n",
    "    hidden_layer = hidden_layer.reshape(hidden_layer.shape[0],1,4).sum(axis=2)\n",
    "    output_layer = np.floor(sigmoid(hidden_layer))  # Passing through the activation function\n",
    "    \n",
    "    return accuracy_score(output_layer,y_test)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00c08cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = model(input_weights,hidden_weights,x_train,y_train,learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c5020ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  89.2\n"
     ]
    }
   ],
   "source": [
    "output = predict(weights,x_test,y_test)\n",
    "print(\"Accuracy score: \",round(output,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f6154a",
   "metadata": {},
   "source": [
    "##### Weight Optimization using Cultural Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "350a7e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating the population\n",
    "population_size = 50\n",
    "population = []\n",
    "for solution in range(population_size):\n",
    "    # Initializing the population with random weights\n",
    "    input_weight = np.random.rand(1,12)\n",
    "    hidden_weight = np.random.rand(1,4)\n",
    "    # Combining the weights\n",
    "    weight = np.append(input_weight,hidden_weight)\n",
    "    weight = weight.reshape(1,16)\n",
    "    population.append(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91801908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dataframe stores the weights & the corresponding accuracy\n",
    "pop_df = pd.DataFrame()\n",
    "pop_df['weights'] = list(population)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "663e57cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConvertToMatrix(solution):\n",
    "    weight = {'input_weight':(solution.reshape(4,4)[:3]).reshape(1,12),\n",
    "             'hidden_weight': solution.reshape(4,4)[-1]}\n",
    "    return weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "54553ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parent_selection(population_size,no_of_parents = 2):\n",
    "    # Tournament selection\n",
    "    # We select 2 parents at random from the population\n",
    "    parents = [np.random.randint(0,population_size) for i in range(no_of_parents)]\n",
    "    return parents # Returns the indices of the population as a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "55108902",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness_function(population,x,y):\n",
    "    # Here we consider the accuracy of the model with a particular set of weights to be the fitness function\n",
    "    fitness_score = []\n",
    "    for solution in population: # We take each set of weights and compute the accuracy \n",
    "        sol = ConvertToMatrix(solution)\n",
    "        fitness_score.append(predict(sol,x,y)) # Returns the accuracy score that set of weights\n",
    "    return fitness_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "20b9a6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a belief system such that we consider only those weights(solutions) that give atleast 85% accuracy\n",
    "def influence(pop_df):\n",
    "    culture_df = pd.DataFrame(columns = ['weights','fitness_value'])\n",
    "    culture_df = pop_df[pop_df['fitness_value'] >= 85] \n",
    "    return culture_df,len(culture_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "60e696ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We take 2 additional parents that follow the belief system(atleast 85% accuracy) to maintain the culture\n",
    "def acceptance(population_size,no_of_parents = 2):\n",
    "    # Tournament selection\n",
    "    # We select 2 parents at random from the culture\n",
    "    parents = [np.random.randint(0,population_size) for i in range(no_of_parents)]\n",
    "    return parents # Returns the indices of the population as a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "420fec38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossover(parent1,parent2,parent3,parent4,culture_df,weight_df):\n",
    "    #Performing single point crossover\n",
    "    # Takes 4 parents - 2 randomly picked & 2 that follow the belief system\n",
    "    \n",
    "    #Generating the split point\n",
    "    split_point = np.random.randint(0,16) # Since there are 16 weights in a solution\n",
    "    \n",
    "    # Performing single point crossover\n",
    "    child1 = np.append(weight_df['weights'][parent1][:split_point],weight_df['weights'][parent2][split_point:])\n",
    "    child1 = child1.reshape(1,16)\n",
    "    \n",
    "    child2 = np.append(weight_df['weights'][parent1][split_point:],weight_df['weights'][parent2][:split_point])\n",
    "    child2 = child2.reshape(1,16)\n",
    "    \n",
    "    child3 = np.append(culture_df['weights'][parent3][:split_point],culture_df['weights'][parent4][split_point:])\n",
    "    child3 = child3.reshape(1,16)\n",
    "    \n",
    "    child4 = np.append(culture_df['weights'][parent3][split_point:],culture_df['weights'][parent4][:split_point])\n",
    "    child4 = child4.reshape(1,16)\n",
    "    \n",
    "    return child1,child2,child3,child4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b0a779ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutation(child1,child2,child3,child4):\n",
    "    # Performing swap mutation\n",
    "    # Generating the indices to swap the weights\n",
    "    indices = [np.random.randint(0,16) for i in range(2)]\n",
    "    \n",
    "    # Swapping the weights at those indices for all the children\n",
    "    child1[0][indices[0]],child1[0][indices[1]] = child1[0][indices[1]],child1[0][indices[0]]\n",
    "    \n",
    "    child2[0][indices[0]],child2[0][indices[1]] = child2[0][indices[1]],child2[0][indices[0]]\n",
    "    \n",
    "    child3[0][indices[0]],child3[0][indices[1]] = child3[0][indices[1]],child3[0][indices[0]]\n",
    "    \n",
    "    child4[0][indices[0]],child4[0][indices[1]] = child4[0][indices[1]],child4[0][indices[0]]\n",
    "    \n",
    "    return child1,child2,child3,child4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3d75e504",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_population(weight_df,children,sol1,sol2,sol3,sol4,x,y):\n",
    "    \n",
    "    # Replacing the solutions having least accuracy with the newly produced offspring\n",
    "    \n",
    "    #Generating the accuracy of the new solutions(offsprings)\n",
    "    fitness_score = fitness_function(children,x,y)\n",
    "    \n",
    "    # Replacing the old solutions in the dataframe with new offsprings\n",
    "    weight_df.loc[sol1,['weights','fitness_value']] = [children[0],fitness_score[0]]\n",
    "    weight_df.loc[sol2,['weights','fitness_value']] = [children[1],fitness_score[1]]\n",
    "    weight_df.loc[sol3,['weights','fitness_value']] = [children[2],fitness_score[2]]\n",
    "    weight_df.loc[sol4,['weights','fitness_value']] = [children[3],fitness_score[3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cd450cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cultural_Algorithm(weight_df,x,y,epoch):\n",
    "    for i in range(epoch):\n",
    "        #Fitness score calculation\n",
    "        weight_df['fitness_value'] = fitness_function(list(weight_df['weights'].values),x,y)\n",
    "        \n",
    "        # Parent selection by random process\n",
    "        parents = parent_selection(population_size,2)\n",
    "        parent1,parent2 = parents[0],parents[1]\n",
    "        \n",
    "        # Parent selection from the culture\n",
    "        culture_population_df,culture_size = influence(weight_df)\n",
    "        culture_parents = acceptance(culture_size,2)\n",
    "        parent3,parent4 = culture_parents[0],culture_parents[1]\n",
    "        \n",
    "        # Crossover operation\n",
    "        child1,child2,child3,child4 = crossover(parent1,parent2,parent3,parent4,culture_population_df,weight_df)\n",
    "        \n",
    "        # Mutation operation\n",
    "        child1,child2,child3,child4 = mutation(child1,child2,child3,child4)\n",
    "        children = np.stack((child1,child2,child3,child4))\n",
    "        \n",
    "        # Sorting the dataframe containing weights & fitness value based on fitness value(accuracy)\n",
    "        weight_df.sort_values(by = 'fitness_value',ascending = False)\n",
    "        \n",
    "        # Generating the indices of the solutions with least accuracy\n",
    "        least_acc1 = len(weight_df)-1\n",
    "        least_acc2 = len(weight_df)-2\n",
    "        least_acc3 = len(weight_df)-3\n",
    "        least_acc4 = len(weight_df)-4\n",
    "        \n",
    "        # Replacing the solutions with least accuracy in the population\n",
    "        replace_population(weight_df,children,least_acc1,least_acc2,least_acc3,least_acc4,x,y)\n",
    "        \n",
    "        # Sorting the dataframe after the addition of new solutions\n",
    "        weight_df.sort_values(by = 'fitness_value',ascending = False)\n",
    "        \n",
    "        # The weights with highest accuracy\n",
    "        best_weight = ConvertToMatrix(weight_df['weights'][0]) \n",
    "        accuracy = weight_df['fitness_value'][0]\n",
    "        \n",
    "        return best_weight,round(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3c18a9c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'input_weight': array([[0.002746  , 0.22805055, 0.24721236, 0.68547584, 0.86076404,\n",
       "          0.58348449, 0.52097235, 0.07803278, 0.36716149, 0.71663317,\n",
       "          0.66139079, 0.53869698]]),\n",
       "  'hidden_weight': array([0.63023787, 0.96537321, 0.16046596, 0.70231835])},\n",
       " 89)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cultural_Algorithm(pop_df,x_test,y_test,100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
